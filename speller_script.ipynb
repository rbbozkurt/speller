{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45405426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/resitberkaybozkurt/opt/anaconda3/lib/python3.9/site-packages/skl2onnx/algebra/onnx_ops.py:159: UserWarning: OpSchema.FormalParameter.typeStr is deprecated and will be removed in 1.16. Use OpSchema.FormalParameter.type_str instead.\n",
      "  tys = obj.typeStr or ''\n",
      "/Users/resitberkaybozkurt/opt/anaconda3/lib/python3.9/site-packages/skl2onnx/algebra/automation.py:154: UserWarning: OpSchema.FormalParameter.isHomogeneous is deprecated and will be removed in 1.16. Use OpSchema.FormalParameter.is_homogeneous instead.\n",
      "  if getattr(obj, 'isHomogeneous', False):\n",
      "/Users/resitberkaybozkurt/opt/anaconda3/lib/python3.9/site-packages/jinja2/environment.py:471: UserWarning: OpSchema.FormalParameter.typeStr is deprecated and will be removed in 1.16. Use OpSchema.FormalParameter.type_str instead.\n",
      "  return getattr(obj, attribute)\n"
     ]
    }
   ],
   "source": [
    "# This is a sample Python script.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Press âŒƒR to execute it or replace it with your code.\n",
    "# Press Double â‡§ to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tslearn.metrics import dtw\n",
    "import string\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from database import SpellerDatabase\n",
    "from database.SpellerDatabase import *\n",
    "import plot.SpellerPlotter as Plotter\n",
    "import SpellerConstant\n",
    "from train import SpellerModel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from train import SpellerTrainer\n",
    "from train import RealTimePeakDetector\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from skl2onnx import convert_sklearn\n",
    "import onnxruntime as rt\n",
    "from skl2onnx.helpers.onnx_helper import save_onnx_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import antropy as ant\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from scipy.fftpack import fft, dct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc26441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dict(letter_list: []):\n",
    "    labels = {}\n",
    "    for num, letter in enumerate(letter_list, start=1):\n",
    "        labels[letter] = float(num)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c67fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LETTERS = list(string.ascii_uppercase)\n",
    "models = ['Summary statistics', 'Sensor data']\n",
    "balance_acc_score = []\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9beab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_frame = SpellerDatabase.read_letters_from_database(SpellerConstant.FIREBASE_REFERENCE,tuple(TARGET_LETTERS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_session(model,X, y, session_desc):\n",
    "    # balance acc score list for different datasets\n",
    "    balance_acc_score = []\n",
    "    models = []\n",
    "    train_scores = []\n",
    "    train_descs = []\n",
    "    # names of the datasets\n",
    "    conf_matrices = []\n",
    "    min = -1\n",
    "    max = 1\n",
    "\n",
    "    # train model with scikitlearn\n",
    "\n",
    "    print(\"------------ Standardizing data with ({},{}) ({}) ------------\".format(min, max, session_desc))\n",
    "    _X = np.nan_to_num(X, copy=True)\n",
    "    _X = SpellerPreProcesser.standardize(_X, min, max)\n",
    "    print(\"------------ Splitting test,train set ({}) ------------\".format(session_desc))\n",
    "    #leave out test data\n",
    "    _X, X_valid, y, y_valid = train_test_split(_X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(\"------------ Training SciKit Model ({}) ------------\".format(session_desc))\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(_X, y)):\n",
    "        X_train = _X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = _X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        model = model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.around(y_pred)\n",
    "        train_descs.append('Fold {}'.format(i))\n",
    "        train_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    mean_of_folds = np.mean(train_scores)\n",
    "    train_scores.append(mean_of_folds)\n",
    "    train_descs.append('Mean of Folds')\n",
    "    print(\"------------ Testing SciKit Model ({}) ------------\".format(session_desc))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred = np.around(y_pred)\n",
    "    train_scores.append(balanced_accuracy_score(y_valid, y_pred))\n",
    "    train_descs.append('Validation')\n",
    "    print(\"------------ Calculating Top-K-Accuray SciKit Model ({}) ------------\".format(session_desc))\n",
    "    #k_values = []\n",
    "    #score = []\n",
    "    #for k in TOP_K_VALUES:\n",
    "     #   k_values.append(k)\n",
    "      #  score.append(SpellerTrainer.calculate_top_k_accuracy(model, _X, y, k))\n",
    "    #print(\"------------ Plotting results of Top-K-Accuracy ------------\")\n",
    "    #plot_bar(score, k_values, \"Top K Accuracy Scores Sk {}\".format(session_desc))\n",
    "\n",
    "    conf_matrix_scikit = confusion_matrix(y_valid, y_pred)\n",
    "    model_desc = \"SK-Test-{}\".format(session_desc)\n",
    "    models.append(model_desc)\n",
    "    conf_matrices.append(conf_matrix_scikit)\n",
    "    Plotter.plot_conf_matrix(conf_matrix_scikit, 'Prediction', 'Actual', 'Confusion {}'.format(model_desc),\n",
    "                             TARGET_LETTERS)\n",
    "\n",
    "    y_pred = model.predict(_X)\n",
    "    y_pred = np.around(y_pred)\n",
    "    conf_matrix_scikit = confusion_matrix(y, y_pred)\n",
    "    model_desc = \"SK-Train-{}\".format(session_desc)\n",
    "    models.append(model_desc)\n",
    "    conf_matrices.append(conf_matrix_scikit)\n",
    "    Plotter.plot_conf_matrix(conf_matrix_scikit, 'Prediction', 'Actual', 'Confusion {}'.format(model_desc),\n",
    "                             TARGET_LETTERS)\n",
    "    \n",
    "    # Plot performance of two models\n",
    "    print(\"------------ Plotting results ------------\")\n",
    "    plot_bar(train_scores, train_descs, \"Balance Accuracy Scores\")\n",
    "\n",
    "    return train_descs, train_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_statistics(data_frame: pd.DataFrame()):\n",
    "    for axes in SENSOR_AXES:\n",
    "        column = data_frame[axes]\n",
    "        Min = []\n",
    "        Max = []\n",
    "        hj_mob_array = []\n",
    "        hj_com_array = []\n",
    "        peak_array0 = []\n",
    "        dip_array0 = []\n",
    "        peak_array1 = []\n",
    "        dip_array1 = []\n",
    "        Mean = []\n",
    "        Rms = []\n",
    "        Var = []\n",
    "        Std = []\n",
    "        Power = []\n",
    "        Peak = []\n",
    "        Skew = []\n",
    "        Kurtosis = []\n",
    "        P2p = []\n",
    "        CrestFactor = []\n",
    "        FormFactor = []\n",
    "        PulseIndicator = []\n",
    "        Max_f = []\n",
    "        Sum_f = []\n",
    "        Mean_f = []\n",
    "        Var_f = []\n",
    "        Peak_f = []\n",
    "        Skew_f = []\n",
    "        Kurtosis_f = []\n",
    "        data_summ_stat = []\n",
    "        for X in column:\n",
    "            ## TIME DOMAIN ##\n",
    "            Min.append(np.min(X))\n",
    "            Max.append(np.max(X))\n",
    "            Mean.append(np.mean(X))\n",
    "            Rms.append(np.sqrt(np.mean(X ** 2)))\n",
    "            Var.append(np.var(X))  # Hjorth's activity\n",
    "            Std.append(np.std(X))\n",
    "            Power.append(np.mean(X ** 2))\n",
    "            Peak.append(np.max(np.abs(X)))\n",
    "            P2p.append(np.ptp(X))\n",
    "            CrestFactor.append(np.max(np.abs(X)) / np.sqrt(np.mean(X ** 2)))\n",
    "            Skew.append(stats.skew(X))\n",
    "            Kurtosis.append(stats.kurtosis(X))\n",
    "            FormFactor.append(np.sqrt(np.mean(X ** 2)) / np.mean(X))\n",
    "            PulseIndicator.append(np.max(np.abs(X)) / np.mean(X))\n",
    "            ## FREQ DOMAIN ##\n",
    "            ft = fft(X)\n",
    "            S = np.abs(ft ** 2) / len(X)\n",
    "            Max_f.append(np.max(S))\n",
    "            Sum_f.append(np.sum(S))\n",
    "            Mean_f.append(np.mean(S))\n",
    "            Var_f.append(np.var(S))\n",
    "            Peak_f.append(np.max(np.abs(S)))\n",
    "            Skew_f.append(stats.skew(X))\n",
    "            Kurtosis_f.append(stats.kurtosis(X))\n",
    "\n",
    "            ## calculate Hjorth Parameters mobility & complexity ##\n",
    "            mob, com = ant.hjorth_params(X)\n",
    "            hj_mob_array.append(mob)\n",
    "            hj_com_array.append(com)\n",
    "            ## peak and dips ##\n",
    "            threshold = (np.max(X) - np.min(X)) / 2\n",
    "            signal0, signal1 = create_peak_dip_arrays(PEAK_DETECTOR_LAG, threshold, X)\n",
    "            peak, dip = count_peak_dip(signal0)\n",
    "            peak_array0.append(peak)\n",
    "            dip_array0.append(dip)\n",
    "            peak, dip = count_peak_dip(signal1)\n",
    "            peak_array1.append(peak)\n",
    "            dip_array1.append(dip)\n",
    "            data_summ_stat.append([])\n",
    "\n",
    "        data_frame['{}_MIN'.format(axes)] = Min\n",
    "        data_frame['{}_MAX'.format(axes)] = Min\n",
    "        data_frame['{}_PEAK_INF0'.format(axes)] = peak_array0\n",
    "        data_frame['{}_DIP_INFf0'.format(axes)] = dip_array0\n",
    "        data_frame['{}_PEAK_INF1'.format(axes)] = peak_array1\n",
    "        data_frame['{}_DIP_INF1'.format(axes)] = dip_array1\n",
    "        data_frame['{}_HJ_MOB'.format(axes)] = hj_mob_array\n",
    "        data_frame['{}_HJ_COM'.format(axes)] = hj_com_array\n",
    "        data_frame['{}_MEAN'.format(axes)] = Mean\n",
    "        data_frame['{}_RMS'.format(axes)] = Rms\n",
    "        data_frame['{}_VAR'.format(axes)] = Var\n",
    "        data_frame['{}_STD'.format(axes)] = Std\n",
    "        data_frame['{}_POWER'.format(axes)] = Power\n",
    "        data_frame['{}_PEAK'.format(axes)] = Peak\n",
    "        data_frame['{}_P2P'.format(axes)] = P2p\n",
    "        data_frame['{}_CREST_FACTOR'.format(axes)] = CrestFactor\n",
    "        data_frame['{}_SKEW'.format(axes)] = Skew\n",
    "        data_frame['{}_KURTOSIS'.format(axes)] = Kurtosis\n",
    "        data_frame['{}_MAX_f'.format(axes)] = Max_f\n",
    "        data_frame['{}_SUM_f'.format(axes)] = Sum_f\n",
    "        data_frame['{}_MEAN_f'.format(axes)] = Mean_f\n",
    "        data_frame['{}_VAR_f'.format(axes)] = Var_f\n",
    "        data_frame['{}_PEAK_f'.format(axes)] = Peak_f\n",
    "        data_frame['{}_SKEW_f'.format(axes)] = Skew_f\n",
    "        data_frame['{}_KURTOSIS_f'.format(axes)] = Kurtosis\n",
    "\n",
    "        data_frame['data_summ_stat'] = data_summ_stat\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295dde54",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_STATISTICS_FEATURES = ['MIN', 'MAX', 'PEAK_INF0', 'DIP_INFf0', 'PEAK_INF1', 'DIP_INF1', 'HJ_MOB', 'HJ_COM',\n",
    "                               'MEAN', 'VAR', 'STD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd61ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_peak_dip(data_array: []):\n",
    "    peak = sum(1 for i in data_array if i > 0)\n",
    "    dip = sum(1 for i in data_array if i < 0)\n",
    "    return peak, dip\n",
    "\n",
    "\n",
    "def create_peak_dip_arrays(lag, threshold, signal_data):\n",
    "    realTimePeakDetector0 = RealTimePeakDetector(signal_data[0:lag], PEAK_DETECTOR_LAG, threshold,\n",
    "                                                 0)\n",
    "    realTimePeakDetector1 = RealTimePeakDetector(signal_data[0:lag], PEAK_DETECTOR_LAG, threshold,\n",
    "                                                 1)\n",
    "\n",
    "    for data_point in signal_data[lag:]:\n",
    "        realTimePeakDetector0.thresholding_algo(data_point)\n",
    "        realTimePeakDetector1.thresholding_algo(data_point)\n",
    "\n",
    "    return realTimePeakDetector0.signals, realTimePeakDetector1.signals\n",
    "\n",
    "def extract_X_y_summ_sta(data_frame: pd.DataFrame()):\n",
    "    for axes in SENSOR_AXES:\n",
    "        for feature in SUMMARY_STATISTICS_FEATURES:\n",
    "            col_name = '{}_{}'.format(axes, feature)\n",
    "            # print(type(data_frame[col_name]))\n",
    "            data_frame['data_summ_stat'] = data_frame['data_summ_stat'].combine(data_frame[col_name],\n",
    "                                                                                (lambda x1, x2: x1 + [x2]))\n",
    "\n",
    "    data = data_frame['data_summ_stat'].tolist()\n",
    "    X = SpellerPreProcesser.standardize(data, -1, 1)\n",
    "    y = data_frame['target'].to_numpy()\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(y_values, x_values, title):\n",
    "    x_pos = np.arange(len(x_values))\n",
    "    y_pos = np.arange(len(y_values))\n",
    "    plt.bar(y_pos, y_values)\n",
    "    plt.xticks(x_pos, x_values,rotation=45, ha='right')\n",
    "    plt.title(title, fontsize=17)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b65843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import SpellerPreProcesser\n",
    "from SpellerConstant import SENSOR_AXES\n",
    "from SpellerConstant import PEAK_DETECTOR_LAG\n",
    "from train.RealTimePeakDetector import RealTimePeakDetector\n",
    "import scipy.stats as stats\n",
    "from scipy.fft import fft, fftfreq, dst\n",
    "\n",
    "# extract X and y values from summ stat data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_summ = create_summary_statistics(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_summ_stat, y_summ_stat = extract_X_y_summ_sta(data_frame_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcf262",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_frame_summ[SENSOR_AXES[-2]].iloc[0]\n",
    "data_dct = dct(data)\n",
    "data_dst = dst(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e47bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fa284",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_dct)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e589d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_STATISTICS_FEATURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K_VALUES = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "lr_model = LogisticRegression(random_state=0, multi_class='multinomial')\n",
    "knn_model = KNeighborsClassifier(n_neighbors=len(TARGET_LETTERS))\n",
    "hgbr_model = HistGradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e049d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_desc_ss, knn_sc_ss = train_session(knn_model,X_summ_stat, y_summ_stat, \"SS_KNN\")\n",
    "lr_desc_ss, lr_sc_ss = train_session(lr_model,X_summ_stat, y_summ_stat, \"SS_LR\")\n",
    "hgbr_desc_ss, hgbr_sc_ss = train_session(hgbr_model,X_summ_stat, y_summ_stat, \"SS_HGBR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598cb4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4875618",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_model_desc_ss, sk_model_sc_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94dd704",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sklearn_knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_acc_score.append(balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_conf_matrix(conf_matrix, 'Prediction', 'Actual', 'Confusion Matrix with SciKit', TARGET_LETTERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = sklearn_knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89193909",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_accuracy_score(y_test, y_prob, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4af2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c313d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tslearn_knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc052ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_acc_score.append(balanced_accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
